{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Twitter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## author: Sergey Ovsianyk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell makes sure that all of the outputs of a cell are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the outputs in a cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell disables autosaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.\"Trump\" keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After collecting tweets from Tweeter, using key word \"*Trump*\", I read the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_file = open(\"../data/Trump.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving all information from file to the string\n",
    "tweets_string = tweets_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closing the file\n",
    "tweets_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since words in our positive, negative and stop lists are lower-case, I converted all tweets to lower-case.\n",
    "tweets_string = tweets_string.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of collected tweets are saved into 1 string right now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating one string of tweets into list of \"words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_words_list = tweets_string.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of dirty words is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94974"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_words_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the file of **positive** words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_file = open('../data/positive.txt','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = positive_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of positive words are saved into 1 string, separated by \\n right now. Separating one string of positive words into list of positive words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = positive_words.split(sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the file of **negative** words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_file = open('../data/negative-words.txt','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = negative_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of negative words are saved into 1 string, separated by \\n right now. Separating one string of negative words into list of negative words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = negative_words.split(sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the file of **stop** words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_file = open('../data/stopwords.txt','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stop_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of stop words are saved into 1 string, separated by \\n right now. Separating one string of stop words into list of stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stop_words.split(sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, I defined a function that removes special characters that I defined and numbers from both sides of the string. After that it checks if each letter of each word is not a special character, except '-'. If it is, remove that word from the list. At the end it checks if word is equal to empty string, or '-' or if it starts with '@', if word meets any of these conditions, word is excluded from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_cleaning(words_list):\n",
    "    \n",
    "    # I did not include '@' to specia characters for a reason.\n",
    "    # I do not want to clean my word form this character to the left of the word.\n",
    "    # In twitter, you can tag a user in your post using @User_name syntax\n",
    "    # That is a reason I left '@' to the left of the word. I still will delete these words, later.\n",
    "    # string of special characters\n",
    "    special_characters = ':.,?/><`~\\\\|\\\"\\';]}[{1234567890±§!#$%^&*)(_='\n",
    "    for index, item in enumerate(words_list):\n",
    "        # delete special symbols from both sides\n",
    "        words_list[index] = words_list[index].rstrip(special_characters + '@')\n",
    "        words_list[index] = words_list[index].lstrip(special_characters)\n",
    "        # for each word in the list\n",
    "    for word in words_list:\n",
    "        # for each letter of each word\n",
    "        for c in word:\n",
    "            # if letter is one of special characters, I delete the word\n",
    "            if ((c in special_characters) & (c != '-')):\n",
    "                words_list.remove(word)\n",
    "                break\n",
    "    for word in words_list:\n",
    "        # if word is empty string, or it is a dash, or it starts with '@', I delete the word\n",
    "        if word == '' or word == '-' or word.startswith('@'):\n",
    "            words_list.remove(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function above, to our list of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cleaning(tweets_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning we have 78985 words\n"
     ]
    }
   ],
   "source": [
    "print('After cleaning we have ' + str(len(tweets_words_list)) + ' words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after the cleaning, there are some dirty words, like in example below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">WARNING: this example is relevant only to the current Trump.txt. Though you can manually inspect the list and see some dirty words. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest\\xe2\\x80\\xa6\\n'b\"rt\n"
     ]
    }
   ],
   "source": [
    "print(tweets_words_list[72])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirty_count(words_list):\n",
    "    dirty = 0\n",
    "    for word in words_list:\n",
    "        if not word.isalpha():\n",
    "            dirty += 1\n",
    "    print(\"Rafly culculating(including all hyphen words). There are \" + str(round((dirty * 100/len(words_list)), 2)) + \"% of dirty words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rafly culculating(including all hyphen words). There are 3.1% of dirty words\n"
     ]
    }
   ],
   "source": [
    "dirty_count(tweets_words_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider it as a noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that counts how many positive, negative, stop words and other word is there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countPosNegStopWords(listOfWords, positiveList, negativeList, stopWordsList):\n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "    stop_word_count = 0\n",
    "    other_count = 0\n",
    "    for word in listOfWords:\n",
    "        if word in positiveList:\n",
    "            positive_count += 1\n",
    "            continue\n",
    "        elif word in negativeList:\n",
    "            negative_count += 1\n",
    "            continue\n",
    "        elif word in stopWordsList:\n",
    "            stop_word_count += 1\n",
    "            continue\n",
    "        else:\n",
    "            other_count += 1\n",
    "    return (positive_count, negative_count, stop_word_count, other_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_count_trump, negative_count_trump, stop_word_count_trump, other_count_trump\\\n",
    "= countPosNegStopWords(tweets_words_list,positive_words,negative_words,stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that performs sentiment analysis on our list of words and prints results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_info(npositive, nnegative, nstop, nother, nall):\n",
    "    ratio = 0\n",
    "    info = ''\n",
    "    sentiment_info = 'In general sentiment is '\n",
    "    if npositive > nnegative:\n",
    "        ratio = npositive/nnegative\n",
    "        info = \"For each negative word there is \" + str(round(ratio,2)) + \" positive words\"\n",
    "        if ratio > 1.4:\n",
    "            sentiment_info += 'strongly positive'\n",
    "        elif ratio > 1.1:\n",
    "            sentiment_info += 'weakly positive'\n",
    "        else:\n",
    "            sentiment_info += 'neutral'\n",
    "    elif nnegative > npositive:\n",
    "        ratio = nnegative/npositive\n",
    "        info = \"For each positive word there is \" + str(round(ratio,2)) + \" negative words\"\n",
    "        if ratio > 1.4:\n",
    "            sentiment_info += 'strongly negative'\n",
    "        elif ratio > 1.1:\n",
    "            sentiment_info += 'weakly negative'\n",
    "        else:\n",
    "            sentiment_info += 'neutral'\n",
    "    else:\n",
    "        ratio = nnegative/npositive\n",
    "        info = \"For each positive word there is \" + str(round(ratio,2)) + \" negative words\"\n",
    "        sentiment_info += 'neutral'\n",
    "    print(info)\n",
    "    print(sentiment_info)\n",
    "    print()\n",
    "    print(\"The sum of positive and negative words = \" + str(npositive + nnegative))\n",
    "    print()\n",
    "    print('There are ' + str(npositive) + ' positive words')\n",
    "    print('There are ' + str(nnegative) + ' negative words')\n",
    "    print('There are ' + str(nstop) + ' stop words')\n",
    "    print('There are ' + str(nother) + ' other words')\n",
    "    print()\n",
    "    print('Ratio of positive words to all words is:' + str(round(npositive/nall,5)))\n",
    "    print('Ratio of negative words to all words is:' + str(round(nnegative/nall,5)))\n",
    "    print('Ratio of stop words to all words is:' + str(round(nstop/nall,5)))\n",
    "    print('Ratio of other words to all words is:' + str(round(nother/nall,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each negative word there is 1.63 positive words\n",
      "In general sentiment is strongly positive\n",
      "\n",
      "The sum of positive and negative words = 8258\n",
      "\n",
      "There are 5118 positive words\n",
      "There are 3140 negative words\n",
      "There are 38924 stop words\n",
      "There are 31803 other words\n",
      "\n",
      "Ratio of positive words to all words is:0.0648\n",
      "Ratio of negative words to all words is:0.03975\n",
      "Ratio of stop words to all words is:0.4928\n",
      "Ratio of other words to all words is:0.40265\n"
     ]
    }
   ],
   "source": [
    "sentiment_info(positive_count_trump, negative_count_trump, stop_word_count_trump, other_count_trump, len(tweets_words_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### However:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'trump' in positive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words.remove('trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_count_trump, negative_count_trump, stop_word_count_trump, other_count_trump\\\n",
    "= countPosNegStopWords(tweets_words_list,positive_words,negative_words,stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each positive word there is 1.16 negative words\n",
      "In general sentiment is weakly negative\n",
      "\n",
      "The sum of positive and negative words = 5858\n",
      "\n",
      "There are 2718 positive words\n",
      "There are 3140 negative words\n",
      "There are 38924 stop words\n",
      "There are 34203 other words\n",
      "\n",
      "Ratio of positive words to all words is:0.03441\n",
      "Ratio of negative words to all words is:0.03975\n",
      "Ratio of stop words to all words is:0.4928\n",
      "Ratio of other words to all words is:0.43303\n"
     ]
    }
   ],
   "source": [
    "sentiment_info(positive_count_trump, negative_count_trump, stop_word_count_trump,\\\n",
    "               other_count_trump, len(tweets_words_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary: after removing word \"trump\" from list of positive words, sentiment changed from strongly positive to weakly negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words.append('trump')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\"covid-19\" keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After collecting tweets from Tweeter, using key word \"*covid-19*\", I read the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_19_file = open(\"../data/covid-19.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving all information from file to the string\n",
    "covid_19_string = covid_19_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closing the file\n",
    "covid_19_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since words in our positive, negative and stop lists are lower-case, I converted all tweets to lower-case.\n",
    "covid_19_string = covid_19_string.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of collected tweets are saved into 1 string right now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating one string of tweets into list of \"words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_19_words_list = covid_19_string.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of dirty words is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45897"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(covid_19_words_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cleaning(covid_19_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning we have 38980 words\n"
     ]
    }
   ],
   "source": [
    "print('After cleaning we have ' + str(len(covid_19_words_list)) + ' words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rafly culculating(including all hyphen words). There are 7.22% of dirty words\n"
     ]
    }
   ],
   "source": [
    "dirty_count(covid_19_words_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_count_covid_19, negative_count_covid_19, stop_word_count_covid_19, other_count_covid_19 =\\\n",
    "countPosNegStopWords(covid_19_words_list, positive_words, negative_words, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each positive word there is 1.06 negative words\n",
      "In general sentiment is neutral\n",
      "\n",
      "The sum of positive and negative words = 2421\n",
      "\n",
      "There are 1173 positive words\n",
      "There are 1248 negative words\n",
      "There are 18139 stop words\n",
      "There are 18420 other words\n",
      "\n",
      "Ratio of positive words to all words is:0.03009\n",
      "Ratio of negative words to all words is:0.03202\n",
      "Ratio of stop words to all words is:0.46534\n",
      "Ratio of other words to all words is:0.47255\n"
     ]
    }
   ],
   "source": [
    "sentiment_info(positive_count_covid_19, negative_count_covid_19, stop_word_count_covid_19,\\\n",
    "               other_count_covid_19, len(covid_19_words_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
